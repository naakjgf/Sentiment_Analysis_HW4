{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4: Sentiment Analysis - Task 2\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names \n",
    "----\n",
    "Names: Kaan Tural, Arinjay Singh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Train a Naive Bayes Model (30 points)\n",
    "----\n",
    "\n",
    "Using `nltk`'s `NaiveBayesClassifier` class, train a Naive Bayes classifier using a Bag of Words as features.\n",
    "https://www.nltk.org/_modules/nltk/classify/naivebayes.html \n",
    "\n",
    "Naive Bayes classifiers use Bayesâ€™ theorem for predictions. Naive Bayes can be a good baseline for NLP applications in particular. You can use it as a baseline for your project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/turalk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# our utility functions\n",
    "# RESTART your jupyter notebook kernel if you make changes to this file\n",
    "import sentiment_utils as sutils\n",
    "\n",
    "# nltk for Naive Bayes and metrics\n",
    "import nltk\n",
    "import nltk.classify.util\n",
    "from nltk.metrics.scores import (precision, recall, f_measure, accuracy)\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "# some potentially helpful data structures from collections\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# so that we can make plots\n",
    "import matplotlib.pyplot as plt\n",
    "# if you want to use seaborn to make plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants for the files we are using\n",
    "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
    "DEV_FILE = \"movie_reviews_dev.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in your data and make sure you understand the format\n",
    "# Do not print out too much so as to impede readability of your notebook\n",
    "train_tups = sutils.generate_tuples_from_file(TRAIN_FILE)\n",
    "dev_tups = sutils.generate_tuples_from_file(DEV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example words: ['The', 'movie', \"'Gung\", 'Ho', '!', \"'\", ':', 'The', 'Story', 'of', 'Carlson', \"'s\", 'Makin', 'Island', 'Raiders', 'was', 'made', 'in', '1943', 'with', 'a', 'view', 'to', 'go', 'up', 'the', 'moral', 'of', 'American', 'people', 'at', 'the', 'duration', 'of', 'second', 'world', 'war', '.', 'It', 'shows', 'with', 'the', 'better', 'way', 'that', 'the', 'cinema', 'can', 'constitute', 'body', 'of', 'propaganda', '.', 'The', 'value', 'of', 'this', 'film', 'is', 'only', 'collection', 'and', 'no', 'artistic', '.', 'In', 'a', 'film', 'of', 'propaganda', 'it', 'is', 'useless', 'to', 'judge', 'direction', 'and', 'actors', '.', 'Watch', 'that', 'movie', 'if', 'you', 'are', 'interested', 'to', 'learn', 'how', 'propaganda', 'functions', 'in', 'the', 'movies', 'or', 'if', 'you', 'are', 'a', 'big', 'fun', 'of', 'Robert', 'Mitchum', 'who', 'has', 'a', 'small', 'role', 'in', 'the', 'film', '.', 'If', 'you', 'want', 'to', 'see', 'a', 'film', 'for', 'the', 'second', 'world', 'war', ',', 'they', 'exist', 'much', 'better', 'and', 'objective', '.', 'I', 'rated', 'it', '4/10', '.']\n",
      "Actual Label: 0\n",
      "Prediction with binarized features: 0\n",
      "Prediction with count-based features: 0\n",
      "\n",
      "Example words: ['After', '2', 'years', 'of', 'using', 'this', 'site', 'for', 'movie', 'reviews', ',', 'I', 'finally', 'registered', 'with', 'IMDB', 'just', 'so', 'I', 'could', 'give', 'Farscape', 'a', '``', '10', '.', \"''\", 'The', 'show', \"'s\", 'writers', ',', 'cast', 'and', 'crew', 'have', 'proven', 'themselves', 'the', 'unambiguous', 'masters', 'of', 'the', 'science', 'fiction', 'genre', '.', 'Even', 'those', 'who', 'do', 'not', 'normally', 'appreciate', 'sci-fi', 'should', 'be', 'encouraged', 'to', 'give', 'this', 'exceptional', 'series', 'a', 'chance', '!', 'Farscape', \"'s\", 'virtues', 'are', 'simply', 'too', 'numerous', 'to', 'list', ',', 'but', 'one', 'of', 'them', 'stands', 'out', 'above', 'all', ';', 'the', 'quality', 'of', 'the', 'writing', 'is', 'amazing', '.', 'I', 'have', \"n't\", 'heard', 'dialogue', 'this', 'good', 'since', '``', 'Blake', \"'s\", '7', '.', \"''\", 'In', 'fact', ',', 'Farscape', 'feels', 'a', 'lot', 'like', 'a', '``', 'Blake', \"'s\", '7', \"''\", 'with', 'good', 'special', 'effects', 'and', 'a', 'bit', 'more', 'romance.Everyone', ',', 'enjoy', '!']\n",
      "Actual Label: 1\n",
      "Prediction with binarized features: 1\n",
      "Prediction with count-based features: 1\n",
      "\n",
      "Example words: ['The', 'only', 'reason', 'any', 'of', 'the', 'hundred', 'or', 'so', 'users', 'watched', 'this', 'movie', 'was', 'because', 'they', 'belong', 'to', 'the', 'crew', ',', 'were', 'friends', 'to', 'the', 'crew', ',', 'or', 'were', 'obsessive', 'fans', 'of', 'either', 'Lance', 'Henriksen', 'or', 'Lorenzo', 'Lamas', '.', 'I', 'personally', 'follow', 'the', '``', 'cult', 'of', 'Lance', \"''\", ',', 'so', 'I', 'was', 'disappointed', 'to', 'see', 'that', 'despite', 'being', 'the', 'headliner', ',', 'it', \"'s\", 'in', 'name', 'only', '.', 'Playing', 'rich', 'criminal', 'Newcastle', ',', 'Lance', 'is', 'a', 'joy', 'to', 'watch', 'but', 'all', 'of', 'his', 'screen', 'time', 'is', 'relegated', 'to', 'the', 'beginning', 'of', 'the', 'movie', '.', 'Newcastle', 'sets', 'up', 'a', '747', 'heist', 'which', 'includes', 'Ketchum', '(', 'Lamas', ')', 'and', 'a', 'bunch', 'of', 'forgettable', 'characters', '.', 'The', 'biggest', 'shock', 'to', 'this', 'viewer', 'was', 'that', 'the', 'pre-heist', 'scenes', 'were', 'not', 'all', 'that', 'bad', '.', 'With', 'the', 'exception', 'of', 'somewhat', 'obnoxious', 'and', 'rather', 'confused', 'looking', 'Aviva', 'Gale', ',', 'who', 'times', 'every', 'line', 'with', 'the', 'finesse', 'of', 'a', 'grade', 'school', 'play', 'actress', ',', 'acting', 'was', 'decent', 'all', 'around', ',', 'and', 'none', 'of', 'the', 'lines', 'really', 'made', 'me', 'cringe.But', 'once', 'the', 'heist', 'occurs', ',', 'the', 'movie', 'falls', 'asleep', '.', 'Not', 'only', 'is', 'their', 'plan', 'the', 'most', 'ridiculous', 'thing', 'ever', 'captured', 'on', 'film', ',', 'but', 'it', \"'s\", 'dragged', 'out', 'for', 'far', 'too', 'long', '.', 'This', 'is', \"n't\", 'a', 'very', 'deep', 'movie', ',', 'and', 'you', 'have', 'to', 'fill', 'out', 'your', '90', 'minutes', ',', 'but', 'these', 'scenes', 'are', 'so', 'boring', 'I', 'nearly', 'nodded', 'off', 'at', 'two', 'in', 'the', 'afternoon', '.', 'One', 'particular', 'sequence', 'in', 'which', 'we', 'watch', 'each', 'and', 'every', 'one', 'of', 'the', 'characters', 'perform', 'the', 'same', 'task', 'over', 'and', 'over', 'again', 'is', 'especially', 'difficult', 'to', 'get', 'through', '.', 'The', 'movie', \"'s\", 'name', 'is', '``', 'Rapid', 'Exchange', \"''\", ',', 'but', 'the', 'exchange', 'is', 'far', 'from', 'rapid', '-', 'it', \"'s\", 'overlong', 'and', 'bloated', 'to', 'extremes', '.', 'Perhaps', 'it', 'would', 'have', 'worked', 'if', 'any', 'of', 'the', 'characters', 'had', 'real', 'personalities', ',', 'but', 'come', 'on', ',', 'there', \"'s\", 'only', 'so', 'much', 'you', 'can', 'ask', 'out', 'of', 'a', 'straight-to-video', 'movie', 'airing', 'of', 'Showtime', 'Extreme.Thankfully', ',', 'there', 'are', 'several', 'laughs', ',', 'intentional', 'and', 'unintentional', '(', 'Lorenzo', 'Lamas', 'is', 'seemingly', 'a', 'master', 'of', 'disguise', ',', 'which', 'makes', 'for', 'a', 'couple', 'of', 'incredibly', 'bizarre', 'scenarios', ')', ',', 'and', 'Lance', 'returns', 'in', 'the', 'film', \"'s\", 'end', ',', 'albeit', 'for', 'a', 'brief', 'period', 'of', 'time', '.', 'It', \"'s\", 'a', 'bad', 'movie', ',', 'and', 'I', 'probably', 'did', \"n't\", 'have', 'to', 'tell', 'you', 'that', 'myself', ',', 'but', 'it', \"'s\", 'far', 'from', 'the', 'worst', 'thing', 'I', \"'ve\", 'ever', 'seen', '.', 'I', 'would', \"n't\", 'put', 'it', 'too', 'high', 'on', 'the', 'list', 'of', 'Henriksen', 'films', ',', 'since', 'he', \"'s\", 'been', 'in', 'some', 'real', 'gems', 'with', 'greater', 'screen', 'time', ',', 'and', 'either', 'way', 'the', 'movie', 'loses', 'a', 'lot', 'of', 'steam', 'once', 'the', 'heist', 'begins', ',', 'but', 'the', 'best', 'thing', 'I', 'can', 'say', 'for', 'Rapid', 'Exchange', 'is', 'that', 'the', 'last', 'two', 'films', 'I', 'watched', 'before', 'it', 'were', 'the', 'mainstream', 'Hostage', 'and', 'the', 'overrated', ',', 'pretentious', 'Crash', '-', 'and', 'this', 'was', 'better', 'than', 'both', '.']\n",
      "Actual Label: 0\n",
      "Prediction with binarized features: 0\n",
      "Prediction with count-based features: 0\n",
      "\n",
      "Example words: ['Four', 'stories', 'about', 'the', 'drug', 'trade', 'in', 'Europe', 'become', 'intertwined', 'over', 'the', 'course', 'of', 'this', '6', 'part', 'miniseries', '.', 'In', 'Germany', 'a', 'businessman', 'is', 'arrested', 'on', 'drug', 'smuggling', 'charges', ',', 'and', 'his', 'wife', 'attempts', 'to', 'save', 'her', 'family', 'by', 'continuing', 'her', 'husband', \"'s\", 'illegal', 'trade', '.', 'Meanwhile', 'the', 'British', 'Home', 'Secretary', 'travels', 'to', 'Pakistan', 'to', 'negotiate', 'an', 'aid', 'package', 'that', 'he', 'hopes', 'will', 'stop', 'the', 'drug', 'flow', 'from', 'that', 'country', '.', 'Even', 'as', 'he', 'does', 'this', 'however', 'his', 'own', 'daughter', 'succumbs', 'to', 'heroin', 'addiction', ',', 'tearing', 'their', 'family', 'apart', '.', 'This', 'is', 'the', 'miniseries', 'on', 'which', 'the', 'American', 'film', 'and', 'miniseries', 'were', 'based', '.', 'The', 'original', 'is', 'far', 'superior', 'to', 'its', 'two', 'decendants', '.', 'The', 'poverty', 'and', 'desperation', 'of', 'the', 'third', 'world', 'are', 'portrayed', 'very', 'well', '.', 'It', 'is', 'stark', ',', 'uncompromising', 'and', 'brutal', '.']\n",
      "Actual Label: 1\n",
      "Prediction with binarized features: 1\n",
      "Prediction with count-based features: 1\n",
      "\n",
      "Example words: ['I', 'give', 'the', 'show', 'a', 'six', 'because', 'of', 'the', 'fact', 'that', 'the', 'show', 'was', 'in', 'fact', 'a', 'platform', 'for', 'Damon', 'Wayans', 'as', 'the', 'Cosby', 'Show', 'was', 'for', 'Bill', 'Cosby', ',', 'it', 'dealt', 'with', 'a', 'lot', 'of', 'issues', 'with', 'humor', 'and', 'I', 'felt', 'that', 'it', 'in', 'fact', 'tailored', 'to', 'getting', 'a', 'laugh', 'as', 'opposed', 'to', 'letting', 'the', 'jokes', 'come', 'from', 'the', 'character', '.', 'Michael', 'Kyle', 'An', 'interesting', 'patriarch', 'and', 'a', 'wisecracking', 'person', '.', 'He', 'is', 'PHENOMENAL', 'in', 'movies', ',', 'but', 'in', 'the', 'show', 'he', 'was', 'there', 'for', 'the', 'wisecrack', 'and', 'though', 'I', 'loved', 'it', ',', 'I', 'felt', 'that', 'the', 'laugh', 'was', 'more', 'important', 'than', 'plausibility.Jay', 'Kyle', 'I', 'have', 'loved', 'her', 'since', 'House', 'Party', 'and', 'have', 'enjoyed', 'her', 'in', 'School', 'Daze', 'and', 'Martin', ',', 'this', 'was', 'a', 'great', 'role', 'for', 'her', 'and', 'she', 'made', 'a', 'great', 'choice', 'in', 'picking', 'this', 'sitcom', 'to', 'co-star', 'in', '.', 'I', 'also', 'feel', 'that', 'Jay', 'and', 'Michael', 'were', 'more', 'like', 'equals', 'in', 'the', 'show', 'but', 'Jay', 'was', 'more', 'the', 'woman', 'who', 'fed', 'her', 'crazy', 'husbands', 'the', 'lines', 'and', 'went', 'along', 'with', 'his', 'way', 'of', 'unorthodox', 'discipline', 'because', 'she', 'may', 'have', 'felt', 'that', 'it', 'workedJr', 'Just', 'plain', 'stupid', ',', 'his', 'character', 'should', 'have', 'been', 'well', 'developed', 'and', 'even', 'though', 'he', 'does', 'have', 'his', 'moments', 'of', 'greatness', ',', 'we', 'are', 'returned', 'to', 'the', 'stupidity', 'as', 'if', 'he', 'learned', 'nothing', ',', 'which', 'drives', 'me', 'nuts', '!', '!', '!', '!', '!', '!', '!', '!', 'Not', 'to', 'mention', 'that', 'most', 'of', 'the', 'situations', '(', 'in', 'episodes', 'I', \"'ve\", 'seen', ')', 'seems', 'to', 'center', 'around', 'himClair', 'The', 'attractive', 'sister', 'who', 'dated', 'a', 'Christian', ',', 'I', 'found', 'her', 'boyfriend', \"'s\", 'character', 'to', 'be', 'more', 'interesting', 'than', 'she', 'was', '(', 'she', \"'d\", 'be', 'better', 'off', 'sticking', 'to', 'movies', ',', 'the', 'writers', 'should', 'have', 'done', 'more', 'to', 'show', 'her', 'intelligence', 'but', 'it', \"'s\", 'not', 'stereotypical', 'enough', ')', 'Kady', 'Lovable', 'and', 'the', 'youngest', 'daughter', '.', 'I', 'think', 'the', 'writers', 'established', 'her', 'character', 'most', 'on', 'the', 'show', 'aside', 'from', 'the', 'parents', 'and', 'FranklinFranklin', 'I', 'LOVE', 'this', 'character', 'and', 'I', 'think', 'they', 'derived', 'it', 'from', 'Smart', 'Guy', '(', 'T.J.', 'Mowry', ')', 'which', 'only', 'lasted', 'one', 'season', '.', 'They', 'did', 'a', 'great', 'job', 'of', 'casting', 'for', 'this', 'little', 'genius', '(', 'the', 'effort', 'would', 'have', 'been', 'made', 'if', 'Jr', 'would', 'have', 'been', 'the', 'smart', 'one', 'but', 'show', 'the', 'down', 'sides', 'also', ')', 'All', 'in', 'all', ',', 'this', 'sitcom', 'is', 'a', 'wonderful', 'thing', 'and', 'it', \"'s\", 'homage', 'to', 'the', 'Cosby', 'Show', 'is', 'well', 'done', ',', 'I', 'love', 'the', 'show', 'and', 'wished', 'it', 'would', 'have', 'stayed', 'on', 'longer', 'than', 'that', '.', 'I', 'ca', \"n't\", 'wait', 'to', 'see', 'the', 'series', 'finale']\n",
      "Actual Label: 0\n",
      "Prediction with binarized features: 0\n",
      "Prediction with count-based features: 0\n",
      "\n",
      "Example words: ['A', 'BDSM', '``', 'sub-culture', \"''\", 'of', 'Los', 'Angeles', 'serves', 'as', 'backdrop', 'for', 'this', 'low', 'budget', 'and', 'shabbily', 'constructed', 'mess', ',', 'plainly', 'a', 'vanity', 'piece', 'for', 'its', 'top-billed', 'player', ',', 'Celia', 'Xavier', ',', 'who', 'also', 'produces', 'and', 'scripts', 'while', 'performing', 'a', 'dual', 'role', 'as', 'twin', 'sisters', 'Vanessa', 'and', 'Celia', '.', 'A', 'question', 'soon', 'develops', 'as', 'to', 'whether', 'or', 'not', 'some', 'rather', 'immoderate', 'camera', ',', 'lighting', 'and', 'editing', 'pyrotechnics', 'can', 'ever', 'reach', 'a', 'point', 'of', 'connection', 'to', 'a', 'weak', 'and', 'often', 'incoherent', 'narrative', 'that', 'will', 'not', 'be', 'taken', 'seriously', 'by', 'a', 'sensate', 'viewer', '.', 'Celia', 'is', 'employed', 'as', 'a', 'highly', 'motivated', 'probation', 'officer', 'for', 'the', 'County', 'of', 'Los', 'Angeles', ',', 'while', 'her', 'evil', 'natured', 'twin', 'has', 'become', 'an', 'iconic', 'figure', 'within', 'her', 'fetishistic', 'world', 'largely', 'because', 'of', 'erotic', 'performances', 'upon', 'CD-ROMS', ',', 'but', 'when', 'disaster', 'befalls', '``', 'Mistress', 'Vanessa', \"''\", ',', 'virtuous', 'Celia', ',', 'determined', 'to', 'unearth', 'her', 'sister', \"'s\", 'vicious', 'attacker', ',', 'begins', 'a', 'new', 'job', 'as', 'a', '``', 'sex', 'slave', \"''\", 'at', 'the', 'private', 'Castle', 'Club', 'where', 'the', 'specialty', 'of', 'the', 'house', 'is', 'a', '``', 'dungeon', 'party', \"''\", '.', 'Two', 'FBI', 'field', 'agents', '(', 'whose', 'deployment', 'to', 'the', 'Vanessa', 'case', 'is', 'ostensibly', 'required', 'due', 'to', 'her', 'involvement', 'with', 'internet', 'BDSM', 'sites', ')', ',', 'in', 'addition', 'to', 'a', 'Los', 'Angeles', 'Police', 'Department', 'homicide', 'detective', ',', 'are', 'assigned', 'to', 'investigate', 'the', 'crime', ',', 'while', 'endeavouring', 'to', 'provide', 'security', 'for', 'Celia', 'whose', 'enthusiastic', 'performance', 'in', 'her', 'new', 'vocation', 'is', 'avidly', 'enough', 'regarded', 'by', 'her', 'customers', 'as', 'to', 'have', 'created', 'conditions', 'of', 'personal', 'danger', 'for', 'her', '.', 'Flaws', 'in', 'logic', 'and', 'continuity', 'abound', ',', 'such', 'as', 'a', 'homicide', 'being', 'allocated', 'to', 'L.A.P.D', '.', \"'s\", 'Operations-South', 'Bureau', ',', 'a', 'region', 'of', 'the', 'metropolis', 'that', 'is', 'far', 'removed', 'from', 'the', 'setting', 'of', 'the', 'film', '.', 'Direction', 'is', 'unfocused', 'and', 'not', 'aided', 'by', 'erratic', 'post-production', 'editing', 'and', 'sound', 'reproduction', '.', 'The', 'mentioned', 'photographic', 'gymnastics', 'culminate', 'with', 'a', 'batty', 'montage', 'near', 'the', 'movie', \"'s\", 'end', 'of', 'prior', 'footage', 'that', 'is', 'but', 'tangentially', 'referent', 'to', 'the', 'scenario', '.', 'One', 'solid', 'acting', 'turn', 'appears', 'among', 'this', 'slag', ':', 'Stan', 'Abe', 'as', 'a', 'zealous', 'FBI', 'agent', '.']\n",
      "Actual Label: 0\n",
      "Prediction with binarized features: 1\n",
      "Prediction with count-based features: 0\n",
      "\n",
      "Example words: ['I', 'watched', 'the', 'DVD', '(', 'called', 'BLACK', 'WIDOW', 'in', 'the', 'U.S.A.', ')', 'and', 'felt', 'afterward', 'that', 'it', 'was', ',', 'indeed', ',', 'a', 'truly', 'awful', 'movie', '.', 'But', 'they', 'must', 'have', 'cut', 'quite', 'a', 'bit', 'out', 'of', 'the', 'original', 'film', ',', 'or', 'I', 'missed', 'a', 'lot', '.', 'The', 'sex', 'scenes', 'had', 'very', 'little', 'vulgarity', 'and', 'no', 'nudity', '(', 'not', 'even', 'a', 'breast', ')', ',', 'but', 'I', \"'ve\", 'read', 'several', 'other', 'comments', 'on', 'IMDb.com', 'mentioning', 'the', 'vulgarity', 'and', 'something', 'about', 'a', 'tampon', '.', 'I', 'did', 'not', 'see', 'anything', 'like', 'that', ',', 'just', 'a', 'bad', ',', 'boring', 'film', 'with', 'unlikable', 'characters', 'and', 'a', 'trite', ',', 'sophomoric', 'plot', '.', 'Giada', 'Colagrande', 'is', 'either', 'paralyzed', 'from', 'the', 'mouth', 'up', 'or', 'Botoxed', 'to', 'the', 'gills', ',', 'and', 'nary', 'an', 'expression', 'touches', 'her', 'face', '.', 'And', 'her', 'name', 'makes', 'me', 'think', 'of', 'super-sizing', 'a', 'beverage', 'at', 'Taco', 'Bell', ':', '``', 'I', \"'ll\", 'have', 'the', 'Cola', 'Grande', '!', \"''\", 'It', 'was', 'actually', 'kind', 'of', 'fun', 'it', 'was', 'so', 'bad', ',', 'I', 'got', 'to', 'play', 'like', 'I', 'was', 'in', 'my', 'own', 'Mystery', 'Science', 'Theater', '3000', ',', 'noting', 'things', 'like', 'the', 'fact', 'that', 'Dafoe', \"'s\", 'skin', 'is', 'too', 'big', 'for', 'his', 'face', '.', 'It', \"'s\", 'really', 'like', 'silly', 'putty', '!']\n",
      "Actual Label: 0\n",
      "Prediction with binarized features: 0\n",
      "Prediction with count-based features: 0\n",
      "\n",
      "Example words: ['I', 'had', 'never', 'heard', 'of', 'Silverwing', 'before', ',', 'then', 'I', 'saw', 'it', 'on', 'Toon', 'Disney', 'and', 'instantly', 'loved', 'it', '!', 'I', 'also', 'think', 'that', 'it', 'is', 'not', 'just', 'for', 'kids', ',', 'and', 'that', 'people', 'of', 'all', 'ages', 'would', 'enjoy', 'it', '.', 'It', 'has', 'a', 'great', 'plot', ',', 'great', 'effect', ',', 'and', 'cool', 'characters', '.', 'I', 'will', 'always', 'love', 'the', 'show', ',', 'and', 'I', 'heard', 'it', 'will', 'be', 'coming', 'on', 'on', 'DVD', 'worldwide', 'soon', ',', 'and', 'I', \"'m\", 'going', 'to', 'get', 'it', '!', 'I', 'have', \"n't\", 'read', 'any', 'of', 'the', 'books', ',', 'but', 'I', 'intend', 'to', '.', 'The', 'show', 'deserves', 'a', '10', 'out', 'of', '10', ',', 'and', 'I', 'hope', 'the', 'books', 'are', 'just', 'as', 'good', '.', 'Well', ',', 'that', \"'s\", 'all', 'I', 'have', 'to', 'say', '.', 'But', 'I', 'still', 'have', '2', 'lines', 'I', 'have', 'to', 'fill', 'up', ',', 'so', '...', 'who', 'do', 'you', 'all', 'think', 'is', 'the', 'coolest', 'character', '?', 'Mine', 'is', 'Shade', ',', 'and', 'my', 'second', 'favorite', 'is', 'Marina', '.']\n",
      "Actual Label: 1\n",
      "Prediction with binarized features: 1\n",
      "Prediction with count-based features: 1\n",
      "\n",
      "Example words: ['I', 'was', 'staying', 'in', 'one', 'night', 'and', 'got', 'extremely', 'bored', 'around', '2:00', 'a.m.', 'so', 'I', 'flipped', 'aimlessly', 'through', 'the', 'channels', 'and', 'happened', 'upon', 'H.B.O', '.', 'where', 'this', '``', 'classic', \"''\", 'was', 'playing', '.', 'Initially', 'I', 'was', 'happy', 'to', 'have', 'caught', 'something', 'at', 'the', 'beginning', ',', 'but', 'my', 'happiness', 'faded', 'about', 'two', 'minutes', 'into', 'the', 'movie', '.', 'The', 'whole', 'movie', 'centered', 'around', 'an', 'unattractive', 'man', 'who', 'had', 'a', 'fear', 'of', 'females', ',', 'four', 'beautiful', 'but', 'empty', 'minded', 'women', 'who', 'worked', 'as', 'waitresses', 'at', 'his', 'uncle', \"'s\", 'diner', ',', 'and', 'his', 'enormously', 'fat', 'and', 'extremely', 'miserable', 'cousin', 'who', 'also', 'works', 'at', 'the', 'diner', '.', 'There', 'are', 'a', 'few', 'strange', 'twists', 'in', 'this', 'movie', 'that', 'make', 'it', 'somewhat', 'interesting', ',', 'but', 'certainly', 'not', 'worth', 'watching', '.', 'Basically', ',', 'if', 'you', 'have', 'nothing', 'to', 'do', 'some', 'night', 'or', 'just', 'ca', \"n't\", 'sleep', 'medication', 'works', 'much', 'better', '.', 'However', 'guys', 'there', 'is', 'a', 'lot', 'of', 'skin', 'so', 'it', 'may', 'be', 'okay', 'to', 'watch', 'with', 'no', 'sound', ',', 'but', 'even', 'that', 'can', 'get', 'annoying']\n",
      "Actual Label: 0\n",
      "Prediction with binarized features: 0\n",
      "Prediction with count-based features: 0\n",
      "\n",
      "Example words: ['Generally', 'I', 'like', 'something', 'light', 'and', 'fun', ',', 'so', 'this', 'film', 'should', \"n't\", 'have', 'appealed', 'to', 'me', '.', 'But', 'it', 'grabbed', 'me', 'from', 'the', 'start', '.', 'The', 'story', 'of', 'a', 'family', \"'s\", 'choices', 'and', 'challenges', 'seem', 'obvious', ',', 'but', 'it', 'raises', 'the', 'question', 'over', 'and', 'over', ':', '``', 'What', 'if', 'it', 'was', 'my', 'family', '?', 'My', 'choice', '?', \"''\", 'I', 'cried', 'and', 'laughed', 'when', 'they', 'did', 'because', 'I', 'really', 'felt', 'what', 'the', 'people', 'involved', 'felt', '.', 'It', 'was', 'in', 'places', 'difficult', 'to', 'watch', ',', 'but', 'more', 'difficult', 'to', 'turn', 'away', '.', 'The', 'story', 'is', 'true', ',', 'and', 'life', 'is', 'sometimes', 'difficult', 'to', 'watch', '!', 'It', 'shows', 'what', 'film-makers', 'can', 'do', 'without', 'sex', ',', 'violence', ',', 'or', 'special', 'effects', ':', 'a', 'good', 'story', 'is', 'a', 'good', 'story', 'all', 'by', 'itself', '.', 'The', 'best', 'and', 'most', 'unpredictable', 'stories', 'are', 'all', 'true', 'ones', '.', 'Like', 'real', 'life', ',', 'you', 'really', 'do', \"n't\", 'know', 'what', \"'ll\", 'happen', 'next', ',', 'or', 'why', 'people', 'do', 'the', 'things', 'that', 'they', 'do', '!']\n",
      "Actual Label: 1\n",
      "Prediction with binarized features: 1\n",
      "Prediction with count-based features: 1\n",
      "\n",
      "Example words: ['really', 'liked', 'the', 'movie']\n",
      "Prediction with binarized features: 1\n",
      "Prediction with count-based features: 1\n",
      "\n",
      "Example words: ['bad', 'movie', 'did', 'not', 'like']\n",
      "Prediction with binarized features: 0\n",
      "Prediction with count-based features: 0\n",
      "\n",
      "Example words: ['what', 'a', 'great', 'movie']\n",
      "Prediction with binarized features: 1\n",
      "Prediction with count-based features: 1\n",
      "\n",
      "Example words: ['terrible', 'movie']\n",
      "Prediction with binarized features: 0\n",
      "Prediction with count-based features: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set up a sentiment classifier using NLTK's NaiveBayesClassifier and \n",
    "# a bag of words as features\n",
    "# take a look at the function in lecture notebook 7 (feel free to copy + paste that function)\n",
    "# the nltk classifier expects a dictionary of features as input where the key is the feature name\n",
    "# and the value is the feature value\n",
    "\n",
    "# need to return a dict to work with the NLTK classifier\n",
    "# Possible problem for students: evaluate the difference \n",
    "# between using binarized features and using counts (non binarized features)\n",
    "\n",
    "def word_feats(words, binary=True):\n",
    "    \"\"\"\n",
    "    Generate a dictionary of word features for input to NLTK's NaiveBayesClassifier.\n",
    "    \n",
    "    Args:\n",
    "        words (list of str): The words from a document.\n",
    "        binary (bool): If True, features are binarized (presence/absence); \n",
    "                       if it's False, features are based on word counts.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary where keys are words, and values are either binary or counts.\n",
    "    \"\"\"\n",
    "    if binary:\n",
    "        return {word: True for word in words}\n",
    "    else:\n",
    "        return {word: words.count(word) for word in set(words)}\n",
    "        \n",
    "\n",
    "\n",
    "# set up & train a sentiment classifier using NLTK's NaiveBayesClassifier and\n",
    "# classify the first example in the dev set as an example\n",
    "# make sure your output is well-labeled\n",
    "\n",
    "def train_classifier(train_data, binary=True):\n",
    "    \"\"\"\n",
    "    Train a Naive Bayes sentiment classifier.\n",
    "    \n",
    "    Args:\n",
    "        train_data (list of (list of str, int)): Training data, each item is a tuple where\n",
    "                                                 the first element is a list of words from a document,\n",
    "                                                 and the second element is the label (e.g., 0 or 1 for negative/positive).\n",
    "        binary (bool): Whether to use binarized features.\n",
    "    \n",
    "    Returns:\n",
    "        NaiveBayesClassifier: The trained NLTK Naive Bayes classifier.\n",
    "    \"\"\"\n",
    "    # transforming the training data into the format expected by NLTK: (features_dict, label)\n",
    "    train_features = [(word_feats(words, binary), label) for words, label in train_data]\n",
    "    \n",
    "    classifier = NaiveBayesClassifier.train(train_features)\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "def classify_example(classifier, example_words, binary=True):\n",
    "    \"\"\"\n",
    "    Classify a new example using the trained classifier.\n",
    "    \n",
    "    Args:\n",
    "        classifier (NaiveBayesClassifier): The trained classifier.\n",
    "        example_words (list of str): The words from the new example to classify.\n",
    "        binary (bool): Whether the classifier was trained on binarized features.\n",
    "    \n",
    "    Returns:\n",
    "        str: The predicted label for the example.\n",
    "    \"\"\"\n",
    "    features = word_feats(example_words, binary)\n",
    "    return classifier.classify(features)\n",
    "\n",
    "# test to make sure that you can train the classifier and use it to classify a new example\n",
    "\n",
    "train_data = sutils.generate_tuples_from_file(TRAIN_FILE)  # Returns (X, y) where X is a list of token lists, and y is a list of labels\n",
    "dev_data = sutils.generate_tuples_from_file(DEV_FILE)\n",
    "\n",
    "train_tups = [(words, label) for words, label in zip(train_data[0], train_data[1])]\n",
    "dev_tups = [(words, label) for words, label in zip(dev_data[0], dev_data[1])]\n",
    "\n",
    "classifier_binary = train_classifier(train_tups, binary=True)\n",
    "\n",
    "classifier_count = train_classifier(train_tups, binary=False)\n",
    "\n",
    "test_subset = dev_tups[:10]  # testing first 10 examples so can be displayed nicely\n",
    "\n",
    "for example, label in test_subset:\n",
    "    prediction_binary = classify_example(classifier_binary, example, binary=True)\n",
    "    prediction_count = classify_example(classifier_count, example, binary=False)\n",
    "    print(f\"Example words: {example}\")\n",
    "    print(f\"Actual Label: {label}\")\n",
    "    print(f\"Prediction with binarized features: {prediction_binary}\")\n",
    "    print(f\"Prediction with count-based features: {prediction_count}\\n\")\n",
    "    \n",
    "dev_data = [\n",
    "    ['really', 'liked', 'the', 'movie'],\n",
    "    ['bad', 'movie', 'did', 'not', 'like'],\n",
    "    ['what', 'a', 'great', 'movie'],\n",
    "    ['terrible', 'movie']\n",
    "]\n",
    "\n",
    "for example in dev_data:\n",
    "    prediction_binary = classify_example(classifier_binary, example, binary=True)\n",
    "    prediction_count = classify_example(classifier_count, example, binary=False)\n",
    "    print(f\"Example words: {example}\")\n",
    "    print(f\"Prediction with binarized features: {prediction_binary}\")\n",
    "    print(f\"Prediction with count-based features: {prediction_count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the provided dev set, evaluate your model with precision, recall, and f1 score as well as accuracy\n",
    "# You may use nltk's implemented `precision`, `recall`, `f_measure`, and `accuracy` functions\n",
    "# (make sure to look at the documentation for these functions!)\n",
    "# you will be creating a similar graph for logistic regression and neural nets, so make sure\n",
    "# you use functions wisely so that you do not have excessive repeated code\n",
    "# write any helper functions you need in sentiment_utils.py (functions that you'll use in your other notebooks as well)\n",
    "\n",
    "\n",
    "# create a graph of your classifier's performance on the dev set as a function of the amount of training data\n",
    "# the x-axis should be the amount of training data (as a percentage of the total training data)\n",
    "# NOTE : make sure one of your experiments uses 10% of the data, you will need this to answer the first question in task 5\n",
    "# the y-axis should be the performance of the classifier on the dev set\n",
    "# the graph should have 4 lines, one for each of precision, recall, f1, and accuracy\n",
    "# the graph should have a legend, title, and axis labels\n",
    "\n",
    "vocab = create_index([word for words, _ in train_tups for word in words])\n",
    "\n",
    "train_feats_binary = [dict(zip(vocab, featurize(vocab, words, binary=True))) for words, _ in train_tups]\n",
    "dev_feats_binary = [dict(zip(vocab, featurize(vocab, words, binary=True))) for words, _ in dev_tups]\n",
    "\n",
    "train_feats_count = [dict(zip(vocab, featurize(vocab, words, binary=False))) for words, _ in train_tups]\n",
    "dev_feats_count = [dict(zip(vocab, featurize(vocab, words, binary=False))) for words, _ in dev_tups]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your model using both a __binarized__ and a __multinomial__ BoW. Use whichever one gives you a better final f1 score on the dev set to produce your graphs.\n",
    "\n",
    "- f1 score binarized: __YOUR ANSWER HERE__\n",
    "- f1 score multinomial: __YOUR ANSWER HERE__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
